{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6dc366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, TimeDistributed, LSTM, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c54df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m= pd.read_csv(\"MAS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1b2a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>annotator</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>tricks</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>video_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-02-16T18:02:27.251588Z</td>\n",
       "      <td>42</td>\n",
       "      <td>191.093</td>\n",
       "      <td>[{\"start\":1.293,\"end\":1.398303794117647,\"chann...</td>\n",
       "      <td>2024-02-16T18:03:31.718760Z</td>\n",
       "      <td>/data/upload/6/a81a1bac-Shot1.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-02-16T18:04:23.525063Z</td>\n",
       "      <td>43</td>\n",
       "      <td>187.233</td>\n",
       "      <td>[{\"start\":2.45,\"end\":2.5644912828054296,\"chann...</td>\n",
       "      <td>2024-02-16T18:06:44.868195Z</td>\n",
       "      <td>/data/upload/6/0da57122-video1.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-02-16T18:13:05.591950Z</td>\n",
       "      <td>44</td>\n",
       "      <td>193.461</td>\n",
       "      <td>[{\"start\":1.279,\"end\":1.4751501617647058,\"chan...</td>\n",
       "      <td>2024-02-16T18:14:35.279174Z</td>\n",
       "      <td>/data/upload/6/8970cb3b-video2.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-02-16T18:22:17.552924Z</td>\n",
       "      <td>46</td>\n",
       "      <td>55.583</td>\n",
       "      <td>[{\"start\":1.18,\"end\":1.3875759298642534,\"chann...</td>\n",
       "      <td>2024-02-16T18:22:45.830788Z</td>\n",
       "      <td>/data/upload/6/454d8cfe-video4.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-02-16T18:27:02.700331Z</td>\n",
       "      <td>47</td>\n",
       "      <td>317.612</td>\n",
       "      <td>[{\"start\":1.33,\"end\":1.35,\"channel\":0,\"labels\"...</td>\n",
       "      <td>2024-02-16T18:28:07.097849Z</td>\n",
       "      <td>/data/upload/6/33f9fd58-video6.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   annotation_id  annotator                   created_at  id  lead_time  \\\n",
       "0              3          1  2024-02-16T18:02:27.251588Z  42    191.093   \n",
       "1              4          1  2024-02-16T18:04:23.525063Z  43    187.233   \n",
       "2              5          1  2024-02-16T18:13:05.591950Z  44    193.461   \n",
       "3              8          1  2024-02-16T18:22:17.552924Z  46     55.583   \n",
       "4              9          1  2024-02-16T18:27:02.700331Z  47    317.612   \n",
       "\n",
       "                                              tricks  \\\n",
       "0  [{\"start\":1.293,\"end\":1.398303794117647,\"chann...   \n",
       "1  [{\"start\":2.45,\"end\":2.5644912828054296,\"chann...   \n",
       "2  [{\"start\":1.279,\"end\":1.4751501617647058,\"chan...   \n",
       "3  [{\"start\":1.18,\"end\":1.3875759298642534,\"chann...   \n",
       "4  [{\"start\":1.33,\"end\":1.35,\"channel\":0,\"labels\"...   \n",
       "\n",
       "                    updated_at                           video_url  \n",
       "0  2024-02-16T18:03:31.718760Z   /data/upload/6/a81a1bac-Shot1.mp4  \n",
       "1  2024-02-16T18:06:44.868195Z  /data/upload/6/0da57122-video1.mp4  \n",
       "2  2024-02-16T18:14:35.279174Z  /data/upload/6/8970cb3b-video2.mp4  \n",
       "3  2024-02-16T18:22:45.830788Z  /data/upload/6/454d8cfe-video4.mp4  \n",
       "4  2024-02-16T18:28:07.097849Z  /data/upload/6/33f9fd58-video6.mp4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34049db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 28 into shape (10,64,64,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m X_test_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_video\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Reshape the data to match the expected input shape of the model\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m X_train_array \u001b[38;5;241m=\u001b[39m X_train_array\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_frames, height, width, channels))\n\u001b[0;32m     36\u001b[0m X_test_array \u001b[38;5;241m=\u001b[39m X_test_array\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_frames, height, width, channels))\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Build the CNN-LSTM model\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 28 into shape (10,64,64,3)"
     ]
    }
   ],
   "source": [
    "# Assuming your data is in the DataFrame 'm' and the 'tricks' column contains the labels\n",
    "# Modify this based on the actual structure of your data\n",
    "\n",
    "# Extract relevant columns\n",
    "X = m[['video_url', 'tricks']]\n",
    "y = m['tricks']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data (you may need to adapt this based on your data structure)\n",
    "# For example, load video frames, extract features, etc.\n",
    "\n",
    "# Replace these placeholders with the actual dimensions of your video frames\n",
    "num_frames = 10  # Replace with the actual number of frames\n",
    "height = 64  # Replace with the actual height of the frames\n",
    "width = 64  # Replace with the actual width of the frames\n",
    "channels = 3  # Replace with the actual number of channels (e.g., 3 for RGB)\n",
    "\n",
    "# Assuming preprocess_video is a function that processes a single video frame\n",
    "def preprocess_video(frame):\n",
    "    # Your preprocessing logic here\n",
    "    processed_frame = frame  # Replace this with your actual processing logic\n",
    "    return processed_frame\n",
    "\n",
    "# Apply the preprocessing function to the video URLs in X_train and X_test\n",
    "X_train['processed_video'] = X_train['video_url'].apply(preprocess_video)\n",
    "X_test['processed_video'] = X_test['video_url'].apply(preprocess_video)\n",
    "\n",
    "# Convert the processed video frames to NumPy arrays\n",
    "X_train_array = np.array(X_train['processed_video'].tolist())\n",
    "X_test_array = np.array(X_test['processed_video'].tolist())\n",
    "\n",
    "# Reshape the data to match the expected input shape of the model\n",
    "X_train_array = X_train_array.reshape((-1, num_frames, height, width, channels))\n",
    "X_test_array = X_test_array.reshape((-1, num_frames, height, width, channels))\n",
    "# Build the CNN-LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# CNN layers\n",
    "model.add(TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=(num_frames, height, width, channels)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "# LSTM layer\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# Note: You need to replace this with the actual preprocessing and loading of your video data\n",
    "# Also, adjust the 'epochs' and 'batch_size' based on your dataset size\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.evaluate(X_test, y_test)[1]\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34863793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b40a655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
